# self-reference
This (useless) program outputs its source code.

Self reference is the basis of the limitations of computational machines (see halting problem), on the other hand some believe that self reference might be the origin of consciousness in humans (we are conscious because we think and we can also think about ourselves thinking). These two are contradictory however(the first is a limitation while the second is significant expansion of functionalities). An interesting question is "what is the relation between the human mind and finite machines?", because the mind is not independent from its material substrate(the proof is that I couldn't be writing this if I drank a bottle on wine first :)). Can the mind solve problems that computers can't(even theoretically)? If so, then it must be more than just a finite machine, which imposes the very hard question "what is that 'more'?". If, on the other hand, the mind is a finite machine, then it means that it is possible to build an artificial one (which is so cool, but still doesn't mean that we could manage it).
A popular idea in the field of artificial intelligence is that what we perceive as intelligence can be described precisely enough to make a machine to simulate it. From the dartmouth workshop proposal "*The study is to proceed on the basis of the conjecture that every aspect of learning or any other feature of intelligence can in principle be so precisely described that a machine can be made to simulate it.*" 
Another very interesting idea that may be tangentially related is Godel's incompleteness theorem: there can be no consistent formal system that is complete. But I don't precisely know why yet, it just feels like it fits lol. If any general artifical intelligence is ever build, it would have to be a formal system and this theorem imposes a limit of formal systems in general.
